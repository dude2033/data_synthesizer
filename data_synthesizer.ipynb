{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# install libraries the first time you are using this notebook by uncommenting the following:\n",
    "#!pip install --upgrade sdv #(v0.18.0)\n",
    "#!pip install sdmetrics #(v0.9.1)\n",
    "#!pip install session_info\n",
    "\n",
    "from sdv.metrics.tabular import KSComplement\n",
    "from sdv.lite import TabularPreset\n",
    "from sdv.evaluation import evaluate\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization:\n",
      "config file read, input is combined.csv\n"
     ]
    }
   ],
   "source": [
    "# This Notebook uses a config file to create interpolated data from an input data set. \n",
    "# The interpolation is customizable by config params. See readme.md for more details.\n",
    "\n",
    "config = pd.read_json(\"config.json\") #config file(dictionary)\n",
    "data_file = config[\"Input File\"][0]\n",
    "\n",
    "target_file = config[\"Output File\"][0]\n",
    "data = pd.read_csv(str(data_file))\n",
    "headers = data.columns\n",
    "\n",
    "feature_dict = config[\"Features\"]\n",
    "\n",
    "features = [] #names of relevant headers\n",
    "for feature in config[\"Features\"].keys():\n",
    "    features.append(feature) # wanted headers\n",
    "\n",
    "allowed_percentage = config[\"Percentage\"][0]\n",
    "number_of_samples = int(config[\"N_samples\"][0])\n",
    "#print(features)\n",
    "\n",
    "print(\"Initialization:\\nconfig file read, input is\", data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting column Neoplasm Histologic Grade because of 76.59% NaNs.\n",
      "Deleting column Treatment Details before PDX because of 94.68% NaNs.\n",
      "configured columns: 18\n",
      "after remowing columns with too many NaNs: 16\n",
      "how many columns have numericals: 3\n"
     ]
    }
   ],
   "source": [
    "#Remove unspecified columns\n",
    "for header in headers:\n",
    "    if not header in features:\n",
    "        data.pop(header)\n",
    "        #print(\"Deleting column\", header, \"because of configuration.\")\n",
    "\n",
    "#Remove columns with to many NaNs\n",
    "headers = data.columns #fixed list of columns we need\n",
    "for header in headers:\n",
    "    nan_percentage = data[header].isna().sum() / len(data[header].index)\n",
    "    #print(\"NaN in % for\", header, \":\", nan_percentage)\n",
    "    if nan_percentage > allowed_percentage:\n",
    "        data.pop(header)\n",
    "        headers = headers.drop(header)\n",
    "        print(\"Deleting column\", header, \"because of\" ,\"{:.2%}\".format(nan_percentage), \"NaNs.\")\n",
    "\n",
    "#removing unwanted nans and interpolating others\n",
    "numericals = []\n",
    "for x in headers:\n",
    "    #print(feature_dict, feature_dict[x][0])\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        numericals.append(x)\n",
    "        \n",
    "print(\"configured columns:\",len(features))\n",
    "print(\"after remowing columns with too many NaNs:\", len(headers))\n",
    "print(\"how many columns have numericals:\", len(numericals))\n",
    "\n",
    "for numerical in numericals:\n",
    "    data[numerical] = pd.to_numeric(data[numerical], errors='coerce')\n",
    "\n",
    "data = data.interpolate(method='pad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in original data: 1542\n",
      "rows for validation: 463\n"
     ]
    }
   ],
   "source": [
    "#create validation set\n",
    "\n",
    "validation_set = data.sample(frac=0.3)\n",
    "#removal = data.sample(frac=0.9)\n",
    "#data = data.drop(removal.index)\n",
    "validation_set.reset_index()\n",
    "\n",
    "print(\"rows in original data:\", len(data))\n",
    "print(\"rows for validation:\", len(validation_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': {'Cancer Type Detailed': {'type': 'categorical'}, 'Mutation Count': {'type': 'numerical', 'subtype': 'integer'}, 'Oncotree Code': {'type': 'categorical'}, 'Overall Survival (Months)': {'type': 'numerical', 'subtype': 'float'}, 'Sample Type': {'type': 'categorical'}, 'Diagnosis Age': {'type': 'numerical', 'subtype': 'integer'}, 'TERT': {'type': 'categorical'}, 'IDH1': {'type': 'categorical'}, 'PABPC3': {'type': 'categorical'}, 'PTEN': {'type': 'categorical'}, 'SPRY3': {'type': 'categorical'}, 'MUC12': {'type': 'categorical'}, 'GXYLT1': {'type': 'categorical'}, 'SMARCA4': {'type': 'categorical'}, 'FAT1': {'type': 'categorical'}, 'MUC5B': {'type': 'categorical'}}, 'constraints': []}\n"
     ]
    }
   ],
   "source": [
    "#Generating Metadata for SV\n",
    "metadata = {}\n",
    "metadata[\"fields\"] = {}\n",
    "\n",
    "for x in headers:\n",
    "    metadata[\"fields\"][x] = {}\n",
    "    metadata[\"fields\"][x][\"type\"] = feature_dict[x][0]\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        metadata[\"fields\"][x][\"subtype\"] = feature_dict[x][1]\n",
    "metadata[\"constraints\"] = []\n",
    "\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to the data and generating data with SDV's TabularPreset\n",
    "#model = TabularPreset(name='FAST_ML', metadata=metadata)\n",
    "def makeData(x):\n",
    "    model = TabularPreset(name='FAST_ML', metadata=metadata) #SDV's FAST_ML preset uses ML to model your data\n",
    "    model.fit(data)\n",
    "\n",
    "    new_data = model.sample(num_rows=number_of_samples)\n",
    "    new_data = new_data.round(decimals = 2)\n",
    "    new_data.to_csv(target_file, index=False)\n",
    "    print(x+1, \".: Writing to\", str(target_file), \"The generated data is\", \n",
    "          \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSComplement'])), \n",
    "          \"accurate to the original data.\",\n",
    "          \"(if unsatisfactory try another config\")# using less or diff. features or more data or removing more NaNs.\")\n",
    "    \n",
    "    return \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSComplement']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making data in iterations:\n",
      "\n",
      "1 .: Writing to output.csv The generated data is 77.67% accurate to the original data. (if unsatisfactory try another config\n",
      "2 .: Writing to output.csv The generated data is 76.58% accurate to the original data. (if unsatisfactory try another config\n",
      "3 .: Writing to output.csv The generated data is 76.28% accurate to the original data. (if unsatisfactory try another config\n",
      "4 .: Writing to output.csv The generated data is 77.09% accurate to the original data. (if unsatisfactory try another config\n",
      "5 .: Writing to output.csv The generated data is 76.94% accurate to the original data. (if unsatisfactory try another config\n",
      "6 .: Writing to output.csv The generated data is 76.99% accurate to the original data. (if unsatisfactory try another config\n",
      "7 .: Writing to output.csv The generated data is 76.79% accurate to the original data. (if unsatisfactory try another config\n",
      "8 .: Writing to output.csv The generated data is 75.79% accurate to the original data. (if unsatisfactory try another config\n",
      "9 .: Writing to output.csv The generated data is 76.95% accurate to the original data. (if unsatisfactory try another config\n",
      "10 .: Writing to output.csv The generated data is 76.86% accurate to the original data. (if unsatisfactory try another config\n",
      "\n",
      "Accuracies from 9 generated results written to 20%NaNs_Interpolated_18Features_1542InputLines.csv for statistical analysis.\n"
     ]
    }
   ],
   "source": [
    "# create the new interpolated data with dynamic file name depending on config params\n",
    "nanInPercent = (allowed_percentage*100).astype(int)\n",
    "nrOfFeatures = len(features)\n",
    "nrOfRows = len(data)\n",
    "dataframe = []\n",
    "filename = str(nanInPercent)+\"%NaNs_Interpolated_\"+str(nrOfFeatures)+\"Features_\"+str(nrOfRows)+\"InputLines.csv\"\n",
    "\n",
    "print(\"Making data in iterations:\\n\")\n",
    "for x in range(0,10):\n",
    "    dataframe.append(makeData(x))\n",
    "   \n",
    "print(\"\\nAccuracies from\", x, \"generated results written to\", filename, \"for statistical analysis.\")\n",
    "\n",
    "file = open(filename, \"w\", newline=\"\")\n",
    "\n",
    "writer = csv.writer(file)\n",
    "\n",
    "for val in dataframe:\n",
    "    writer.writerow([val])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for session info uncomment lins below\n",
    "#!pip install session_info\n",
    "#print jupyter session used for the output above\n",
    "#import session_info\n",
    "#session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
