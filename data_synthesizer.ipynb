{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# install libraries the first time you are using this notebook, \n",
    "# you can skip the installation process later by commenting the following three lines:\n",
    "!pip install sdv==0.18.0\n",
    "!pip install sdmetric==v0.9.1\n",
    "\n",
    "from sdv.metrics.tabular import KSComplement\n",
    "from sdv.lite import TabularPreset\n",
    "from sdv.evaluation import evaluate\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Notebook uses a config file to create interpolated data from an input data set. \n",
    "# The interpolation is customizable by config params. See readme.md for more details.\n",
    "\n",
    "config = pd.read_json(\"config.json\") #config file(dictionary)\n",
    "data_file = config[\"Input File\"][0]\n",
    "\n",
    "target_file = config[\"Output File\"][0]\n",
    "data = pd.read_csv(str(data_file), sep=config[\"Input Column Separator\"][0])\n",
    "headers = data.columns\n",
    "\n",
    "feature_dict = config[\"Features\"]\n",
    "\n",
    "features = [] #names of relevant headers\n",
    "for feature in config[\"Features\"].keys():\n",
    "    features.append(feature) # wanted headers\n",
    "\n",
    "allowed_percentage = config[\"Percentage\"][0]\n",
    "number_of_samples = int(config[\"N_samples\"][0])\n",
    "print(features)\n",
    "\n",
    "print(\"Initialization:\\nconfig file read, input is taken from file with name '\",data_file, \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configured columns: 8\n",
      "after removing columns with too many NaNs: 2\n",
      "how many columns have numericals: 0\n",
      "---------------------------------------------------------------------\n",
      " Please specify at least one numerical column for input in config.json!\n"
     ]
    }
   ],
   "source": [
    "#Remove unspecified columns\n",
    "for header in headers:\n",
    "    if not header in features:\n",
    "        data.pop(header)\n",
    "        #print(\"Deleting column\", header, \"because of configuration.\")\n",
    "\n",
    "#Remove columns with to many NaNs\n",
    "headers = data.columns #fixed list of columns we need\n",
    "for header in headers:\n",
    "    nan_percentage = data[header].isna().sum() / len(data[header].index)\n",
    "    #print(\"NaN in % for\", header, \":\", nan_percentage)\n",
    "    if nan_percentage > allowed_percentage:\n",
    "        data.pop(header)\n",
    "        headers = headers.drop(header)\n",
    "        print(\"Deleting column\", header, \"because of\" ,\"{:.2%}\".format(nan_percentage), \"NaNs.\")\n",
    "\n",
    "#removing unwanted nans and interpolating others\n",
    "numericals = []\n",
    "for x in headers:\n",
    "    #print(feature_dict, feature_dict[x][0])\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        numericals.append(x)\n",
    "        \n",
    "print(\"configured columns:\",len(features))\n",
    "print(\"after removing columns with too many NaNs:\", len(headers))\n",
    "print(\"how many columns have numericals:\", len(numericals))\n",
    "if len(numericals)<1:\n",
    "    print(\"---------------------------------------------------------------------\\n\", \n",
    "          \"Please specify at least one numerical column for input in config.json!\")\n",
    "else:\n",
    "    for numerical in numericals:\n",
    "        data[numerical] = pd.to_numeric(data[numerical], errors='coerce')\n",
    "    \n",
    "    data = data.interpolate(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in original data: 66\n",
      "rows for validation: 20\n"
     ]
    }
   ],
   "source": [
    "#create validation set\n",
    "\n",
    "validation_set = data.sample(frac=0.3)\n",
    "#removal = data.sample(frac=0.9)\n",
    "#data = data.drop(removal.index)\n",
    "validation_set.reset_index()\n",
    "\n",
    "print(\"rows in original data:\", len(data))\n",
    "print(\"rows for validation:\", len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': {'chemical_formula': {'type': 'categorical'}, 'metabolite_identification': {'type': 'categorical'}}, 'constraints': []}\n"
     ]
    }
   ],
   "source": [
    "#Generating Metadata for SV\n",
    "metadata = {}\n",
    "metadata[\"fields\"] = {}\n",
    "\n",
    "for x in headers:\n",
    "    metadata[\"fields\"][x] = {}\n",
    "    metadata[\"fields\"][x][\"type\"] = feature_dict[x][0]\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        metadata[\"fields\"][x][\"subtype\"] = feature_dict[x][1]\n",
    "metadata[\"constraints\"] = []\n",
    "\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fit preparation ...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "#Fit model to the data and generating data with SDV's TabularPreset\n",
    "#model = TabularPreset(name='FAST_ML', metadata=metadata)\n",
    "print(\"model fit preparation ...\")\n",
    "def makeData(x):\n",
    "    model = TabularPreset(name='FAST_ML', metadata=metadata) #SDV's FAST_ML preset uses ML to model your data\n",
    "    model.fit(data)\n",
    "\n",
    "    new_data = model.sample(num_rows=number_of_samples)\n",
    "    new_data = new_data.round(decimals = 2)\n",
    "    new_data.to_csv(target_file, index=False)\n",
    "    print(x+1, \".: Writing to\", str(target_file), \"The generated data is\", \n",
    "          \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSComplement'])), \n",
    "          \"accurate to the original data.\",\n",
    "          \"(if unsatisfactory try another config)\")# using less or diff. features or more data or removing more NaNs.\")\n",
    "    \n",
    "    return \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSComplement']))\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "2 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "3 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "4 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "5 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "6 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "7 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "8 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "9 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n",
      "10 .: Writing to output_NMR.csv The generated data is nan% accurate to the original data. (if unsatisfactory try another config)\n"
     ]
    }
   ],
   "source": [
    "# create the new interpolated data with dynamic file name depending on config params\n",
    "nanInPercent = (allowed_percentage*100).astype(int)\n",
    "nrOfFeatures = len(features)\n",
    "nrOfRows = len(data)\n",
    "dataframe = []\n",
    "filename = str(nanInPercent)+\"%NaNs_Interpolated_\"+str(nrOfFeatures)+\"Features_\"+str(nrOfRows)+\"InputLines.csv\"\n",
    "\n",
    "print(\"Making data in iterations:\\n\")\n",
    "for x in range(0,10):\n",
    "    dataframe.append(makeData(x))\n",
    "\n",
    "print(\"\\nAccuracies from\", x+1, \"generated results written to\", filename, \"for statistical analysis.\")\n",
    "print(\"\\nThe actual newly generated output with synthetically generated data has been successfully written to\",target_file,\".\")\n",
    "print(\"Use it to hand it over to someone else or tweak your synthetic data by achanging the config.\")\n",
    "\n",
    "file = open(filename, \"w\", newline=\"\")\n",
    "\n",
    "writer = csv.writer(file)\n",
    "\n",
    "for val in dataframe:\n",
    "    writer.writerow([val])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
