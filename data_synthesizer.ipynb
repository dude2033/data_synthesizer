{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# install libraries the first time you are using this notebook by uncommenting the following:\n",
    "#!pip install sdv\n",
    "#!pip install sdmetrics\n",
    "#!pip install session_info\n",
    "\n",
    "from sdv.metrics.tabular import KSTest\n",
    "from sdv.lite import TabularPreset\n",
    "from sdv.evaluation import evaluate\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: config file read, input is combined.csv\n"
     ]
    }
   ],
   "source": [
    "# This Notebook uses a config file to create interpolated data from an input data set. \n",
    "# The interpolation is customizable by config params. See readme.md for more details.\n",
    "\n",
    "config = pd.read_json(\"config.json\") #config file(dictionary)\n",
    "data_file = config[\"Input File\"][0]\n",
    "\n",
    "target_file = config[\"Output File\"][0]\n",
    "data = pd.read_csv(str(data_file))\n",
    "headers = data.columns\n",
    "\n",
    "feature_dict = config[\"Features\"]\n",
    "\n",
    "features = [] #names of relevant headers\n",
    "for feature in config[\"Features\"].keys():\n",
    "    features.append(feature) # wanted headers\n",
    "\n",
    "allowed_percentage = config[\"Percentage\"][0]\n",
    "number_of_samples = int(config[\"N_samples\"][0])\n",
    "#print(features)\n",
    "\n",
    "print(\"initialization: config file read, input is\", data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unspecified columns\n",
    "for header in headers:\n",
    "    if not header in features:\n",
    "        data.pop(header)\n",
    "        #print(\"Deleting column\", header, \"because of configuration.\")\n",
    "\n",
    "#Remove columns with to many NaNs\n",
    "headers = data.columns #fixed list of columns we need\n",
    "for header in headers:\n",
    "    nan_percentage = data[header].isna().sum() / len(data[header].index)\n",
    "    #print(\"NaN in % for\", header, \":\", nan_percentage)\n",
    "    if nan_percentage > allowed_percentage:\n",
    "        data.pop(header)\n",
    "        headers = headers.drop(header)\n",
    "        print(\"Deleting column\", header, \"because of\" ,\"{:.2%}\".format(nan_percentage), \"NaNs.\")\n",
    "\n",
    "#removing unwanted nans and interpolating others\n",
    "numericals = []\n",
    "for x in headers:\n",
    "    #print(feature_dict, feature_dict[x][0])\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        numericals.append(x)\n",
    "\n",
    "for numerical in numericals:\n",
    "    data[numerical] = pd.to_numeric(data[numerical], errors='coerce')\n",
    "\n",
    "data = data.interpolate(method='pad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in original data: 1542\n",
      "rows for validation: 463\n"
     ]
    }
   ],
   "source": [
    "#create validation set\n",
    "\n",
    "validation_set = data.sample(frac=0.3)\n",
    "#removal = data.sample(frac=0.9)\n",
    "#data = data.drop(removal.index)\n",
    "validation_set.reset_index()\n",
    "\n",
    "print(\"rows in original data:\", len(data))\n",
    "print(\"rows for validation:\", len(validation_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': {'Cancer Type Detailed': {'type': 'categorical'}, 'Mutation Count': {'type': 'numerical', 'subtype': 'integer'}, 'Oncotree Code': {'type': 'categorical'}, 'Overall Survival (Months)': {'type': 'numerical', 'subtype': 'float'}, 'Sample Type': {'type': 'categorical'}, 'Diagnosis Age': {'type': 'numerical', 'subtype': 'integer'}, 'Neoplasm Histologic Grade': {'type': 'categorical'}, 'Treatment Details before PDX': {'type': 'categorical'}, 'TERT': {'type': 'categorical'}, 'IDH1': {'type': 'categorical'}, 'PABPC3': {'type': 'categorical'}, 'PTEN': {'type': 'categorical'}, 'SPRY3': {'type': 'categorical'}, 'MUC12': {'type': 'categorical'}, 'GXYLT1': {'type': 'categorical'}, 'SMARCA4': {'type': 'categorical'}, 'FAT1': {'type': 'categorical'}, 'MUC5B': {'type': 'categorical'}}, 'constraints': []}\n"
     ]
    }
   ],
   "source": [
    "#Generating Metadata for SV\n",
    "metadata = {}\n",
    "metadata[\"fields\"] = {}\n",
    "\n",
    "for x in headers:\n",
    "    metadata[\"fields\"][x] = {}\n",
    "    metadata[\"fields\"][x][\"type\"] = feature_dict[x][0]\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        metadata[\"fields\"][x][\"subtype\"] = feature_dict[x][1]\n",
    "metadata[\"constraints\"] = []\n",
    "\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to the data and generating data with SDV's TabularPreset\n",
    "#model = TabularPreset(name='FAST_ML', metadata=metadata)\n",
    "def makeData():\n",
    "    model = TabularPreset(name='FAST_ML', metadata=metadata) #SDV's FAST_ML preset uses ML to model your data\n",
    "    model.fit(data)\n",
    "\n",
    "    new_data = model.sample(num_rows=number_of_samples)\n",
    "    new_data = new_data.round(decimals = 2)\n",
    "    new_data.to_csv(target_file, index=False)\n",
    "\n",
    "    return \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSTest']))\n",
    "\n",
    "    print(\"The generated data is\", \n",
    "          \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSTest'])), \n",
    "          \"accurate to the original data. \",\n",
    "          \"If this is unsatisfactory try using less or different features, more data or removing more NaNs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making data\n"
     ]
    }
   ],
   "source": [
    "# create the new interpolated data with dynamic file name depending on config params\n",
    "nanInPercent = (allowed_percentage*100).astype(int)\n",
    "nrOfFeatures = len(features)\n",
    "nrOfRows = len(data)\n",
    "dataframe = []\n",
    "filename = str(nanInPercent)+\"%NaNs_Interpolated_\"+str(nrOfFeatures)+\"Features_\"+str(nrOfRows)+\"InputLines.csv\"\n",
    "\n",
    "print(\"making data\")\n",
    "for x in range(0,1000):\n",
    "    dataframe.append(makeData())\n",
    "   \n",
    "print(\"writing to \", filename)\n",
    "\n",
    "file = open(filename, \"w\", newline=\"\")\n",
    "\n",
    "writer = csv.writer(file)\n",
    "\n",
    "for val in dataframe:\n",
    "    writer.writerow([val])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install session_info\n",
    " print jupyter session used for the output above\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
