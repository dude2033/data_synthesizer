{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sdv.lite import TabularPreset\n",
    "from sdv.evaluation import evaluate\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config.csv\"\n",
    "config = pd.read_csv(config_file)\n",
    "data_file = config[\"Input File\"][0]\n",
    "target_file = config[\"Output File\"][0]\n",
    "data = pd.read_csv(data_file)\n",
    "headers = data.columns\n",
    "features = config[\"Features\"].to_list()\n",
    "allowed_percentage = config[\"Percentage\"][0]\n",
    "number_of_samples = int(config[\"Number of Samples\"][0])\n",
    "types = config[\"Type\"].to_list()\n",
    "sub_types = config[\"Subtype\"].to_list()\n",
    "primary_key = config[\"Primary Key\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting column Mutation Count because of 0.23% NaNs.\n",
      "Deleting column Sample Type because of 2.56% NaNs.\n",
      "Deleting column Neoplasm Histologic Grade because of 91.28% NaNs.\n",
      "Deleting column Treatment Details before PDX because of 90.58% NaNs.\n",
      "Index(['Cancer Type Detailed', 'Oncotree Code', 'Overall Survival (Months)',\n",
      "       'Diagnosis Age', 'TERT', 'IDH1', 'PTEN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Remove unspecified columns\n",
    "for header in headers:\n",
    "    if not header in features:\n",
    "        data.pop(header)\n",
    "        #print(\"Deleting column\", header, \"because of configuration.\")\n",
    "\n",
    "#Remove columns with to many NaNs\n",
    "headers = data.columns\n",
    "for header in headers:\n",
    "    nan_percentage = data[header].isna().sum()/len(data[header].index)\n",
    "    if nan_percentage > allowed_percentage:\n",
    "        data.pop(header)\n",
    "        headers = headers.drop(header)\n",
    "        print(\"Deleting column\", header, \"because of\" ,\"{:.2%}\".format(nan_percentage), \"NaNs.\")\n",
    "\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': {'Cancer Type Detailed': {'type': 'categorical'}, 'Oncotree Code': {'type': 'categorical'}, 'Overall Survival (Months)': {'type': 'numerical', 'subtype': 'float'}, 'Diagnosis Age': {'type': 'numerical', 'subtype': 'integer'}, 'TERT': {'type': 'categorical'}, 'IDH1': {'type': 'categorical'}, 'PTEN': {'type': 'categorical'}}, 'constraints': []}\n"
     ]
    }
   ],
   "source": [
    "#Generating Metadata\n",
    "\n",
    "#metadata = {}\n",
    "#metadata[\"fields\"] = {}\n",
    "#for i in range(len(features)):\n",
    "#    if features[i] in headers:\n",
    "#        metadata[\"fields\"][features[i]] = {}\n",
    "#        metadata[\"fields\"][features[i]][\"type\"] = types[i]\n",
    "#        if sub_types[i] == sub_types[i]:\n",
    "#            metadata[\"fields\"][features[i]][\"subtype\"] = sub_types[i]\n",
    "\n",
    "#metadata[\"constraints\"] = []\n",
    "\n",
    "#print(metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There are non-numerical values in your data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jeremias/HCI/data_synthesizer.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeremias/HCI/data_synthesizer.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39m#fit a model to the data and generating data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeremias/HCI/data_synthesizer.ipynb#ch0000007?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m TabularPreset(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFAST_ML\u001b[39m\u001b[39m'\u001b[39m, metadata\u001b[39m=\u001b[39mmetadata)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jeremias/HCI/data_synthesizer.ipynb#ch0000007?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeremias/HCI/data_synthesizer.ipynb#ch0000007?line=5'>6</a>\u001b[0m new_data \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39msample(num_rows\u001b[39m=\u001b[39mnumber_of_samples)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeremias/HCI/data_synthesizer.ipynb#ch0000007?line=7'>8</a>\u001b[0m new_data \u001b[39m=\u001b[39m new_data\u001b[39m.\u001b[39mround(decimals \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sdv/lite/tabular.py:126\u001b[0m, in \u001b[0;36mTabularPreset.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m num_nulls \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    123\u001b[0m             \u001b[39m# Store null percentage for future reference.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_null_percentages[column] \u001b[39m=\u001b[39m num_nulls \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(column_data)\n\u001b[0;32m--> 126\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mfit(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sdv/tabular/base.py:157\u001b[0m, in \u001b[0;36mBaseTabularModel.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mget_dtypes(ids\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    155\u001b[0m     LOGGER\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    156\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m model to table \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mname)\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(transformed)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sdv/tabular/copulas.py:250\u001b[0m, in \u001b[0;36mGaussianCopula._fit\u001b[0;34m(self, table_data)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    249\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m, module\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscipy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mfit(table_data)\n\u001b[1;32m    252\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_metadata()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/copulas/__init__.py:253\u001b[0m, in \u001b[0;36mcheck_valid_values.<locals>.decorated\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYour dataset is empty.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (np\u001b[39m.\u001b[39missubdtype(W\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(W\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger)):\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThere are non-numerical values in your data.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(W)\u001b[39m.\u001b[39many()\u001b[39m.\u001b[39many():\n\u001b[1;32m    256\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThere are nan values in your data.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: There are non-numerical values in your data."
     ]
    }
   ],
   "source": [
    "#fit a model to the data and generating data\n",
    "#model = TabularPreset(name='FAST_ML', metadata=metadata)\n",
    "model = TabularPreset(name='FAST_ML')\n",
    "\n",
    "model.fit(data)\n",
    "\n",
    "new_data = model.sample(num_rows=number_of_samples)\n",
    "\n",
    "new_data = new_data.round(decimals = 2)\n",
    "\n",
    "new_data.to_csv(target_file, index=False)\n",
    "\n",
    "print(\"The generated dat is\", \"{:.2%}\".format(evaluate(new_data, data, metrics=['CSTest'])), \"accurate to the original data. If this is unsatisfactory try using less or different features, more data or removing more NaNs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
