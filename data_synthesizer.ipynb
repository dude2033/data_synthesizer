{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sdv.lite import TabularPreset\n",
    "from sdv.evaluation import evaluate\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: config file read, input is combined.csv\n"
     ]
    }
   ],
   "source": [
    "# This Notebook uses a config file to create interpolated data from an input data set. \n",
    "# The interpolation is customizable by config params. See readme.md for more details.\n",
    "\n",
    "config = pd.read_json(\"config.json\") #config file(dictionary)\n",
    "data_file = config[\"Input File\"][0]\n",
    "\n",
    "target_file = config[\"Output File\"][0]\n",
    "data = pd.read_csv(str(data_file))\n",
    "headers = data.columns\n",
    "\n",
    "feature_dict = config[\"Features\"]\n",
    "\n",
    "features = [] #names of relevant headers\n",
    "for feature in config[\"Features\"].keys():\n",
    "    features.append(feature) # wanted headers\n",
    "\n",
    "allowed_percentage = config[\"Percentage\"][0]\n",
    "number_of_samples = int(config[\"N_samples\"][0])\n",
    "#print(features)\n",
    "\n",
    "print(\"initialization: config file read, input is\", data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting column Neoplasm Histologic Grade because of 76.59% NaNs.\n",
      "Deleting column Treatment Details before PDX because of 94.68% NaNs.\n"
     ]
    }
   ],
   "source": [
    "#Remove unspecified columns\n",
    "for header in headers:\n",
    "    if not header in features:\n",
    "        data.pop(header)\n",
    "        #print(\"Deleting column\", header, \"because of configuration.\")\n",
    "\n",
    "#Remove columns with to many NaNs\n",
    "headers = data.columns #fixed list of columns we need\n",
    "for header in headers:\n",
    "    nan_percentage = data[header].isna().sum() / len(data[header].index)\n",
    "    #print(\"NaN in % for\", header, \":\", nan_percentage)\n",
    "    if nan_percentage > allowed_percentage:\n",
    "        data.pop(header)\n",
    "        headers = headers.drop(header)\n",
    "        print(\"Deleting column\", header, \"because of\" ,\"{:.2%}\".format(nan_percentage), \"NaNs.\")\n",
    "\n",
    "#removing unwanted nans and interpolating others\n",
    "numericals = []\n",
    "for x in headers:\n",
    "    #print(feature_dict, feature_dict[x][0])\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        numericals.append(x)\n",
    "\n",
    "for numerical in numericals:\n",
    "    data[numerical] = pd.to_numeric(data[numerical], errors='coerce')\n",
    "\n",
    "data = data.interpolate(method='pad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in original data: 1542\n",
      "rows for validation: 463\n"
     ]
    }
   ],
   "source": [
    "#create validation set\n",
    "\n",
    "validation_set = data.sample(frac=0.3)\n",
    "#removal = data.sample(frac=0.9)\n",
    "#data = data.drop(removal.index)\n",
    "validation_set.reset_index()\n",
    "\n",
    "print(\"rows in original data:\", len(data))\n",
    "print(\"rows for validation:\", len(validation_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Metadata for SV\n",
    "metadata = {}\n",
    "metadata[\"fields\"] = {}\n",
    "\n",
    "for x in headers:\n",
    "    metadata[\"fields\"][x] = {}\n",
    "    metadata[\"fields\"][x][\"type\"] = feature_dict[x][0]\n",
    "    if feature_dict[x][0] == \"numerical\":\n",
    "        metadata[\"fields\"][x][\"subtype\"] = feature_dict[x][1]\n",
    "metadata[\"constraints\"] = []\n",
    "\n",
    "#print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to the data and generating data with SDV's TabularPreset\n",
    "#model = TabularPreset(name='FAST_ML', metadata=metadata)\n",
    "def makeData():\n",
    "    model = TabularPreset(name='FAST_ML', metadata=metadata) #SDV's FAST_ML preset uses ML to model your data\n",
    "    model.fit(data)\n",
    "\n",
    "    new_data = model.sample(num_rows=number_of_samples)\n",
    "    new_data = new_data.round(decimals = 2)\n",
    "    new_data.to_csv(target_file, index=False)\n",
    "\n",
    "    return \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSTest']))\n",
    "\n",
    "    print(\"The generated data is\", \n",
    "          \"{:.2%}\".format(evaluate(new_data, validation_set, metrics=['KSTest'])), \n",
    "          \"accurate to the original data. \",\n",
    "          \"If this is unsatisfactory try using less or different features, more data or removing more NaNs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making data\n",
      "writing to  10%NaNs_Interpolated_18Features_1542InputLines.csv\n"
     ]
    }
   ],
   "source": [
    "# create the new interpolated data with dynamic file name depending on config params\n",
    "nanInPercent = (allowed_percentage*100).astype(int)\n",
    "nrOfFeatures = len(features)\n",
    "nrOfRows = len(data)\n",
    "dataframe = []\n",
    "filename = str(nanInPercent)+\"%NaNs_Interpolated_\"+str(nrOfFeatures)+\"Features_\"+str(nrOfRows)+\"InputLines.csv\"\n",
    "\n",
    "print(\"making data\")\n",
    "for x in range(0,1000):\n",
    "    dataframe.append(makeData())\n",
    "   \n",
    "print(\"writing to \", filename)\n",
    "\n",
    "file = open(filename, \"w\", newline=\"\")\n",
    "\n",
    "writer = csv.writer(file)\n",
    "\n",
    "for val in dataframe:\n",
    "    writer.writerow([val])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "pandas              1.4.0\n",
       "sdv                 0.15.0\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "asttokens                   NA\n",
       "astunparse                  1.6.3\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "colorama                    0.4.3\n",
       "copulas                     0.7.0\n",
       "ctgan                       0.5.1\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "entrypoints                 0.4\n",
       "executing                   0.8.3\n",
       "faker                       9.9.1\n",
       "google                      NA\n",
       "graphviz                    0.20.1\n",
       "importlib_metadata          NA\n",
       "ipykernel                   6.15.2\n",
       "ipython_genutils            0.2.0\n",
       "ipywidgets                  7.7.0\n",
       "jedi                        0.18.1\n",
       "joblib                      1.1.0\n",
       "jupyter_server              1.18.1\n",
       "llvmlite                    0.38.0\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numba                       0.55.1\n",
       "numpy                       1.21.5\n",
       "packaging                   21.3\n",
       "parso                       0.8.3\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.20\n",
       "psutil                      5.9.0\n",
       "pure_eval                   0.2.2\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.14.0\n",
       "pythoncom                   NA\n",
       "pyts                        0.12.0\n",
       "pytz                        2022.1\n",
       "pywintypes                  NA\n",
       "rdt                         0.6.4\n",
       "scipy                       1.7.3\n",
       "sdmetrics                   0.5.0\n",
       "setuptools                  63.4.1\n",
       "six                         1.16.0\n",
       "sklearn                     1.1.0\n",
       "stack_data                  0.2.0\n",
       "text_unidecode              NA\n",
       "threadpoolctl               3.1.0\n",
       "torch                       1.10.2\n",
       "tornado                     6.2\n",
       "tqdm                        4.64.0\n",
       "traitlets                   5.1.1\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32security               NA\n",
       "yaml                        5.4.1\n",
       "zipp                        NA\n",
       "zmq                         23.2.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.4.0\n",
       "jupyter_client      7.3.5\n",
       "jupyter_core        4.10.0\n",
       "jupyterlab          3.4.4\n",
       "notebook            6.4.12\n",
       "-----\n",
       "Python 3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.22621-SP0\n",
       "-----\n",
       "Session information updated at 2023-02-19 20:25\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install session_info\n",
    "# print jupyter session used for the output above\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
